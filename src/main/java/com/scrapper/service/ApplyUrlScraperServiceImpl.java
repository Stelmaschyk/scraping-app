package com.scrapper.service;

import com.scrapper.model.Job;
import com.scrapper.service.criteriaServices.DescriptionIngestService;
import com.scrapper.util.ScrapingSelectors;
import lombok.RequiredArgsConstructor;
import lombok.extern.slf4j.Slf4j;
import org.openqa.selenium.By;
import org.openqa.selenium.WebDriver;
import org.openqa.selenium.WebElement;
import org.openqa.selenium.support.ui.ExpectedConditions;
import org.openqa.selenium.support.ui.WebDriverWait;
import org.springframework.beans.factory.annotation.Value;
import org.springframework.stereotype.Service;
import java.time.Duration;
import java.time.LocalDateTime;
import java.util.ArrayList;
import java.util.List;
import java.util.Objects;
import java.util.stream.Collectors;

import com.scrapper.service.criteriaServices.DataExtractionService;
import com.scrapper.service.criteriaServices.DateParsingService;
import com.scrapper.service.webdriver.WebDriverService;


/** –õ–û–ì–Ü–ö–ê –§–Ü–õ–¨–¢–†–ê–¶–Ü–á:
 * 1. –°–ø–æ—á–∞—Ç–∫—É –≤–∏–±–∏—Ä–∞—î—Ç—å—Å—è job Function (—Ñ—ñ–ª—å—Ç—Ä–∞—Ü—ñ—è –∑–∞ —Ñ—É–Ω–∫—Ü—ñ—è–º–∏)
 * 2. –ü–æ—Ç—ñ–º –Ω–∞—Ç–∏—Å–∫–∞—î—Ç—å—Å—è –∫–Ω–æ–ø–∫–∞ Load More –û–î–ò–ù —Ä–∞–∑ (—è–∫—â–æ –≤–æ–Ω–∞ —î)
 * 3. –î–∞–ª—ñ –∑–∞–ø—É—Å–∫–∞—î—Ç—å—Å—è —Ü–∏–∫–ª –Ω–µ—Å–∫—ñ–Ω—á–µ–Ω–Ω–æ—ó –ø—Ä–æ–∫—Ä—É—Ç–∫–∏ –∑ –∞–≤—Ç–æ–º–∞—Ç–∏—á–Ω–∏–º –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è–º
 * 4. –í–∏—Ö–æ–¥–∏–º–æ –∑ —Ü–∏–∫–ª—É —Ç—ñ–ª—å–∫–∏ –∫–æ–ª–∏ –∫—ñ–ª—å–∫—ñ—Å—Ç—å –≤–∞–∫–∞–Ω—Å—ñ–π –ø–µ—Ä–µ—Å—Ç–∞—î –∑—Ä–æ—Å—Ç–∞—Ç–∏
 * 5. –Ü —Ç—ñ–ª—å–∫–∏ –ø–æ—Ç—ñ–º –∑—á–∏—Ç—É–≤–∞–Ω–Ω—è URL —Ç–∞ –ø–µ—Ä–µ–≤—ñ—Ä–∫–∞ –ø—Ä–µ—Ñ—ñ–∫—Å—É
 * 6. –Ø–∫—â–æ URL –º—ñ—Å—Ç–∏—Ç—å https://jobs.techstars.com/companies/ —Ç–æ –≤–∞–∫–∞–Ω—Å—ñ—è –∑–±–µ—Ä—ñ–≥–∞—î—Ç—å—Å—è
 * 8. –¢–µ–≥–∏ –∑–±–∏—Ä–∞—é—Ç—å—Å—è –¥–ª—è –≤—Å—ñ—Ö –∑–±–µ—Ä–µ–∂–µ–Ω–∏—Ö –≤–∞–∫–∞–Ω—Å—ñ–π
 */
@Service
@RequiredArgsConstructor
@Slf4j
public class ApplyUrlScraperServiceImpl implements ApplyUrlScraperService {

    @Value("${scraping.base-url:https://jobs.techstars.com/jobs}")
    private String baseUrl;

    @Value("${scraping.selenium.timeout:30}")
    private long timeoutSeconds;

    @Value("${scraping.selenium.scroll.delay:10000}")
    private long scrollDelay;

    @Value("${scraping.selenium.scroll.max-attempts:20}")
    private int maxScrollAttempts;

    @Value("${scraping.selenium.scroll.max-no-new-jobs:3}")
    private int maxNoNewJobsAttempts;

    /**
     * ‚úÖ –ö–õ–Æ–ß–û–í–ê –ö–û–ù–°–¢–ê–ù–¢–ê: –ü—Ä–µ—Ñ—ñ–∫—Å URL –∫–æ–º–ø–∞–Ω—ñ–π Techstars
     * <p>
     * –Ø–∫—â–æ URL –≤–∞–∫–∞–Ω—Å—ñ—ó –º—ñ—Å—Ç–∏—Ç—å —Ü–µ–π –ø—Ä–µ—Ñ—ñ–∫—Å, —Ç–æ –≤–∞–∫–∞–Ω—Å—ñ—è –∑–±–µ—Ä—ñ–≥–∞—î—Ç—å—Å—è
     * –ë–ï–ó –ø–µ—Ä–µ–≤—ñ—Ä–∫–∏ —Ç–µ–≥—ñ–≤ (—Ç—ñ–ª—å–∫–∏ —Ñ—ñ–ª—å—Ç—Ä–∞—Ü—ñ—è –∑–∞ —Ñ—É–Ω–∫—Ü—ñ—è–º–∏).
     * <p>
     * –¢–µ–≥–∏ –∑–±–∏—Ä–∞—é—Ç—å—Å—è –¥–ª—è –≤—Å—ñ—Ö –∑–±–µ—Ä–µ–∂–µ–Ω–∏—Ö –≤–∞–∫–∞–Ω—Å—ñ–π.
     * <p>
     * –¶–µ –¥–æ–∑–≤–æ–ª—è—î –∑–±–µ—Ä—ñ–≥–∞—Ç–∏ –≤—Å—ñ –≤–∞–∫–∞–Ω—Å—ñ—ó –∫–æ–º–ø–∞–Ω—ñ–π Techstars,
     * –Ω–µ–∑–∞–ª–µ–∂–Ω–æ –≤—ñ–¥ —Ç–µ–≥—ñ–≤, –ø—ñ—Å–ª—è –∑–∞—Å—Ç–æ—Å—É–≤–∞–Ω–Ω—è –Ω–æ–≤–æ—ó –≥—ñ–±—Ä–∏–¥–Ω–æ—ó –ª–æ–≥—ñ–∫–∏
     * –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è (Load More + –Ω–µ—Å–∫—ñ–Ω—á–µ–Ω–Ω–∞ –ø—Ä–æ–∫—Ä—É—Ç–∫–∞).
     */
    private static final String REQUIRED_PREFIX = "https://jobs.techstars.com/companies/";

    private final DescriptionIngestService descriptionIngestService;
    private final JobCreationService jobCreationService;
    private final DateParsingService dateParsingService;
    private final DataExtractionService dataExtractionService;
    private final WebDriverService webDriverService;
    private final PageInteractionService pageInteractionService;

    private WebDriver initializeWebDriver() {
        log.info("üîß Initializing Chrome WebDriver using WebDriverService...");
        return webDriverService.createWebDriver();
    }

    @Override
    public List<String> fetchApplyUrls(List<String> jobFunctions) {
        Objects.requireNonNull(jobFunctions, "jobFunctions cannot be null");

        log.info("üöÄ Starting Selenium scraping with NEW LOGIC: jobFunctions={}",
            jobFunctions);

        WebDriver driver = null;
        try {
            driver = initializeWebDriver();
            log.info("üìç Navigating to base URL: {}", baseUrl);
            driver.get(baseUrl);
            log.info("‚è≥ Quick page load...");
            pageInteractionService.sleep(3000);
            String pageTitle = driver.getTitle();
            String currentUrl = driver.getCurrentUrl();
            log.info("üìÑ Page loaded - Title: '{}', URL: '{}'", pageTitle, currentUrl);
            int initialElements = driver.findElements(By.cssSelector("*")).size();
            log.info("üîç Total elements on page: {}", initialElements);
            if (initialElements < 50) {
                log.warn("‚ö†Ô∏è Page seems to be empty! Only {} elements found", initialElements);
                pageInteractionService.sleep(2000);
            }

            // ‚úÖ –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ –ª–æ–≥—ñ–∫—É –∑ –ø—Ä–∞–≤–∏–ª—å–Ω–∏–º –ø–æ—Ä—è–¥–∫–æ–º
            log.info("üîç Applying NEW HYBRID LOGIC: 1) job functions ‚Üí 2) Load More (–û–î–ò–ù —Ä–∞–∑) ‚Üí "
                + "3) –Ω–µ—Å–∫—ñ–Ω—á–µ–Ω–Ω–∞ –ø—Ä–æ–∫—Ä—É—Ç–∫–∞ ‚Üí 4) URL ‚Üí 5) –ø—Ä–µ—Ñ—ñ–∫—Å –∫–æ–º–ø–∞–Ω—ñ—ó ‚Üí 6) –∑–±—ñ—Ä —Ç–µ–≥—ñ–≤");
            List<Job> jobs = scrapeAllJobsWithImprovedLogic(driver, jobFunctions);

            log.info("‚úÖ Scraping completed with NEW LOGIC. Found {} jobs matching criteria.",
                jobs.size());

            return jobs.stream()
                .map(Job::getJobPageUrl)
                .filter(url -> url != null && url.startsWith(REQUIRED_PREFIX))
                .collect(Collectors.toList());

        } catch (Exception e) {
            log.error("‚ùå Error during Selenium scraping", e);
            throw new RuntimeException("Failed to scrape jobs with Selenium", e);
        } finally {
            if (driver != null) {
                webDriverService.closeWebDriver(driver);
            }
        }
    }

    @Override
    public List<Job> scrapeAndCreateJobs(List<String> jobFunctions) {
        log.info("üöÄ Starting job scraping and creation with NEW LOGIC for job functions: {}",
            jobFunctions);

        WebDriver driver = null;
        try {
            driver = initializeWebDriver();
            log.info("üåê WebDriver initialized successfully");

            driver.get(baseUrl);
            log.info("üåê Moving to: {}", baseUrl);

            log.info("üîç Waiting for load page...");
            pageInteractionService.sleep(5000);

            log.info("üîç Quick job cards searching...");
            boolean pageLoaded = false;

            // –°–ø—Ä–æ–±—É—î–º–æ —Ç—ñ–ª—å–∫–∏ –æ—Å–Ω–æ–≤–Ω—ñ —Å–µ–ª–µ–∫—Ç–æ—Ä–∏ –∑ –∫–æ—Ä–æ—Ç–∫–∏–º —Ç–∞–π–º–∞—É—Ç–æ–º
            for (String selector : ScrapingSelectors.JOB_CARD) {
                try {
                    // –ó–º–µ–Ω—à—É—î–º–æ —Ç–∞–π–º–∞—É—Ç –¥–æ 3 —Å–µ–∫—É–Ω–¥
                    WebDriverWait wait = new WebDriverWait(driver, Duration.ofSeconds(3));
                    wait.until(ExpectedConditions.presenceOfElementLocated(By.cssSelector(selector)));

                    int elementCount = driver.findElements(By.cssSelector(selector)).size();
                    if (elementCount > 0) {
                        log.info("‚úÖ Found {} job cards with selector: '{}'", elementCount,
                            selector);
                        pageLoaded = true;
                        break;
                    }
                } catch (Exception e) {
                    log.debug("‚ö†Ô∏è Selector '{}' not found: {}", selector, e.getMessage());
                }
            }

            // ‚úÖ –°–ü–†–û–©–ï–ù–ê –õ–û–ì–Ü–ö–ê: –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ —Ç—ñ–ª—å–∫–∏ –≥–æ–ª–æ–≤–Ω—É —Å—Ç–æ—Ä—ñ–Ω–∫—É
            log.info("üîç Using main page scraping logic: 1) job functions ‚Üí 2) Load More ‚Üí 3) scrolling ‚Üí 4) URL ‚Üí 5) company prefix");
            List<Job> jobs = scrapeAllJobsWithImprovedLogic(driver, jobFunctions);

            log.info("üéØ Job scraping completed with NEW LOGIC. Created {} Job objects with real "
                + "data", jobs.size());
            return jobs;

        } catch (Exception e) {
            log.error("‚ùå Error during job scraping: {}", e.getMessage(), e);
            return new ArrayList<>();
        } finally {
            if (driver != null) {
                webDriverService.closeWebDriver(driver);
            }
        }
    }



    /**
     * –û—Å–Ω–æ–≤–Ω–∞ –ª–æ–≥—ñ–∫–∞ —Å–∫—Ä–∞–ø—ñ–Ω–≥—É –∑ –≥–æ–ª–æ–≤–Ω–æ—ó —Å—Ç–æ—Ä—ñ–Ω–∫–∏:
     * 1. –ó–∞—Å—Ç–æ—Å—É–≤–∞–Ω–Ω—è —Ñ—ñ–ª—å—Ç—Ä—ñ–≤ job functions
     * 2. –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –≤—Å—ñ—Ö –≤–∞–∫–∞–Ω—Å—ñ–π (Load More + –ø—Ä–æ–∫—Ä—É—Ç–∫–∞)
     * 3. –û–±—Ä–æ–±–∫–∞ –∫–∞—Ä—Ç–æ–∫ —Ç–∞ –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è –≤–∞–∫–∞–Ω—Å—ñ–π
     */
    private List<Job> scrapeAllJobsWithImprovedLogic(WebDriver driver, List<String> jobFunctions) {
        log.info("üîç –ó–∞—Å—Ç–æ—Å–æ–≤—É—î–º–æ —Ñ—ñ–ª—å—Ç—Ä–∏ –¥–ª—è job functions: {}", jobFunctions);
        
        boolean anyFilterApplied = false;
        
        if (jobFunctions != null && !jobFunctions.isEmpty()) {
            for (String function : jobFunctions) {
                boolean filterApplied = pageInteractionService.clickJobFunctionFilter(driver, function);
                
                if (filterApplied) {
                    anyFilterApplied = true;
                    log.info("‚úÖ –§—ñ–ª—å—Ç—Ä '{}' –∑–∞—Å—Ç–æ—Å–æ–≤–∞–Ω–æ", function);
                    try {
                        Thread.sleep(3000);
                    } catch (InterruptedException e) {
                        Thread.currentThread().interrupt();
                    }
                } else {
                    log.warn("‚ö†Ô∏è –ù–µ –≤–¥–∞–ª–æ—Å—è –∑–∞—Å—Ç–æ—Å—É–≤–∞—Ç–∏ —Ñ—ñ–ª—å—Ç—Ä '{}'", function);
                }
            }
        }

        if (anyFilterApplied) {
            try {
                Thread.sleep(5000);
            } catch (InterruptedException e) {
                Thread.currentThread().interrupt();
            }
        }

        // –û—Ç—Ä–∏–º—É—î–º–æ –∑–∞–≥–∞–ª—å–Ω—É –∫—ñ–ª—å–∫—ñ—Å—Ç—å –≤–∞–∫–∞–Ω—Å—ñ–π
        log.info("üîç –û—Ç—Ä–∏–º—É—î–º–æ –∑–∞–≥–∞–ª—å–Ω—É –∫—ñ–ª—å–∫—ñ—Å—Ç—å –≤–∞–∫–∞–Ω—Å—ñ–π...");
        int totalJobsExpected = pageInteractionService.getTotalJobCountFromTextAfterFiltering(driver);

        // –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ –≤—Å—ñ –¥–æ—Å—Ç—É–ø–Ω—ñ –≤–∞–∫–∞–Ω—Å—ñ—ó
        log.info("üîç –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ –≤—Å—ñ –¥–æ—Å—Ç—É–ø–Ω—ñ –≤–∞–∫–∞–Ω—Å—ñ—ó (–æ—á—ñ–∫—É—î—Ç—å—Å—è: {})...", totalJobsExpected);
        pageInteractionService.loadAllAvailableJobs(driver, totalJobsExpected);
        log.info("üîç –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –≤–∞–∫–∞–Ω—Å—ñ–π –∑–∞–≤–µ—Ä—à–µ–Ω–æ");

        // –®—É–∫–∞—î–º–æ –≤—Å—ñ –∫–∞—Ä—Ç–∫–∏ –≤–∞–∫–∞–Ω—Å—ñ–π
        log.info("üîç –®—É–∫–∞—î–º–æ –≤—Å—ñ –∫–∞—Ä—Ç–∫–∏ –≤–∞–∫–∞–Ω—Å—ñ–π –ø—ñ—Å–ª—è –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è...");
        List<WebElement> jobCards = pageInteractionService.findJobCardsWithMultipleStrategies(driver);
        List<Job> jobs = new ArrayList<>();

        log.info("üìã Found {} job cards to process", jobCards.size());

        if (jobCards.isEmpty()) {
            log.error("‚ùå CRITICAL: No job cards found with any strategy!");
            return jobs;
        }

        int passedFunctionFilter = 0;
        int foundUrls = 0;
        int savedWithCompanyPrefix = 0;
        int savedWithoutCompanyPrefix = 0;

        for (int i = 0; i < jobCards.size(); i++) {
            try {
                WebElement card = jobCards.get(i);

                // –û–±—Ä–æ–±–ª—è—î–º–æ –≤—Å—ñ –∫–∞—Ä—Ç–∫–∏
                passedFunctionFilter++;

                // –ü–æ—à—É–∫ URL
                String jobPageUrl = pageInteractionService.findDirectJobUrl(card);
                if (jobPageUrl == null) {
                    continue;
                }

                foundUrls++;

                // –ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è –≤–∞–∫–∞–Ω—Å—ñ—ó
                Job job = createJobFromCard(card, jobPageUrl, jobFunctions);
                if (job != null) {
                    jobs.add(job);
                    if (jobPageUrl.startsWith(REQUIRED_PREFIX)) {
                        savedWithCompanyPrefix++;
                    } else {
                        savedWithoutCompanyPrefix++;
                    }
                }

                // –õ–æ–≥—É—î–º–æ –ø—Ä–æ–≥—Ä–µ—Å —Ä—ñ–¥—à–µ - –∫–æ–∂–Ω—ñ 50 –∫–∞—Ä—Ç–æ–∫
                if ((i + 1) % 50 == 0) {
                    log.info("Processed {}/{} job cards", i + 1, jobCards.size());
                }

            } catch (Exception e) {
                log.warn("Error scraping job card {}: {}", i + 1, e.getMessage());
            }
        }
        // –§—ñ–Ω–∞–ª—å–Ω–∏–π –∑–≤—ñ—Ç
        log.info("üìä –ó–í–Ü–¢: {} –∑ {} –∫–∞—Ä—Ç–æ–∫ –æ–±—Ä–æ–±–ª–µ–Ω–æ | URL: {} | –ó–±–µ—Ä–µ–∂–µ–Ω–æ: {} (–∑ –ø—Ä–µ—Ñ—ñ–∫—Å–æ–º: {}, –±–µ–∑ –ø—Ä–µ—Ñ—ñ–∫—Å—É: {}) | –§—É–Ω–∫—Ü—ñ—ó: {}",
            jobs.size(), jobCards.size(), foundUrls, jobs.size(), savedWithCompanyPrefix, savedWithoutCompanyPrefix, jobFunctions);

        log.info("üéØ Job scraping completed with MULTIPLE FILTERS LOGIC. Created {} Job objects with real data", jobs.size());
        return jobs;
    }

    private Job createJobFromCard(WebElement card, String jobPageUrl, List<String> jobFunctions) {
        try {
            String organizationTitle = dataExtractionService.extractCompanyName(card);
            String positionName = dataExtractionService.extractTitle(card);
            List<String> tags = dataExtractionService.extractTags(card);
            String location = dataExtractionService.extractLocation(card);
            LocalDateTime postedDate = dataExtractionService.extractPostedDate(card);
            String logoUrl = dataExtractionService.extractLogoUrl(card);
            String description = dataExtractionService.extractDescription(card);

            String defaultFunction = jobFunctions.isEmpty() ?
                "Software Engineering" : jobFunctions.get(0);

            // ‚úÖ –í–ò–ü–†–ê–í–õ–ï–ù–û: –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ JobCreationService –¥–ª—è —Å—Ç–≤–æ—Ä–µ–Ω–Ω—è Job –∑ —É—Å—ñ–º–∞ –¥–∞–Ω–∏–º–∏
            Job job = jobCreationService.createJobWithAllData(
                jobPageUrl, positionName, organizationTitle, logoUrl, location, tags, postedDate,
                jobFunctions, description
            );

            // –ó–±–µ—Ä—ñ–≥–∞—î–º–æ –æ–ø–∏—Å –≤–∞–∫–∞–Ω—Å—ñ—ó (—Ç—ñ–ª—å–∫–∏ —è–∫—â–æ —Ü–µ –Ω–µ –∑–∞–≥–ª—É—à–∫–∞)
            if (job != null && description != null && !description.trim().isEmpty() &&
                !description.equals("Job scraped from Techstars")) {
                try {
                    descriptionIngestService.saveDescription(job, description);
                } catch (Exception e) {
                    log.warn("‚ö†Ô∏è Error saving description for job ID: {}: {}", job.getId(), e.getMessage());
                }
            }

            return job;

        } catch (Exception e) {
            log.warn("‚ö†Ô∏è Error creating Job object: {}", e.getMessage());
            return null;
        }
    }



}
